```
version: "3.9"

x-airflow-common:
  &airflow-common
  image: apache/airflow:3.0.4-python3.12
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ""
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    _PIP_ADDITIONAL_REQUIREMENTS: "requests prometheus_client pyyaml"
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./config:/opt/airflow/config
  user: "${AIRFLOW_UID:-50000}:0"

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  redis:
    image: redis:7

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"
    depends_on:
      - postgres
      - redis

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    depends_on:
      - postgres
      - redis

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    depends_on:
      - postgres
      - redis

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db init &&
        airflow users create \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com
    depends_on:
      - postgres
      - redis

  pushgateway:
    image: prom/pushgateway
    ports:
      - "9091:9091"

  prometheus:
    image: prom/prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-storage:/var/lib/grafana

volumes:
  postgres-db-volume:
  grafana-storage:
```

```
monitoring/prometheus.yml

global:
  scrape_interval: 15s

scrape_configs:
  - job_name: "pushgateway"
    static_configs:
      - targets: ["pushgateway:9091"]
```
```
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import requests
import time
import os
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway
import yaml

# Load providers from config
CONFIG_PATH = os.path.join(os.path.dirname(__file__), "..", "config", "providers.yaml")
with open(CONFIG_PATH, "r") as f:
    providers = yaml.safe_load(f)["providers"]

# ENV VARS (from .env or Airflow Variables)
PORTKEY_API_KEY = os.getenv("PORTKEY_API_KEY")
PUSHGATEWAY_URL = os.getenv("PUSHGATEWAY_URL", "http://pushgateway:9091")

default_args = {
    "owner": "airflow",
    "retries": 1,
    "retry_delay": timedelta(minutes=2),
}

def benchmark_provider(provider, model, **context):
    """Send test prompt via Portkey Gateway and push metrics to Prometheus Pushgateway"""
    url = "https://api.portkey.ai/v1/chat/completions"

    headers = {
        "Authorization": f"Bearer {PORTKEY_API_KEY}",
        "Content-Type": "application/json",
        # Portkey specific headers
        "x-portkey-provider": provider,
        "x-portkey-model": model,
    }

    payload = {
        "messages": [
            {"role": "user", "content": "Write a haiku about Kubernetes monitoring."}
        ],
        "max_tokens": 50,
    }

    registry = CollectorRegistry()
    latency_gauge = Gauge("llm_latency_seconds", "LLM response latency", ["provider", "model"], registry=registry)
    cost_gauge = Gauge("llm_cost_usd", "LLM response cost (USD)", ["provider", "model"], registry=registry)
    success_gauge = Gauge("llm_request_success", "LLM request success (1=success, 0=failure)", ["provider", "model"], registry=registry)

    try:
        start_time = time.time()
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        latency = time.time() - start_time

        if response.status_code == 200:
            data = response.json()

            # Extract cost if available (Portkey may return it in headers or metadata)
            cost = float(response.headers.get("x-portkey-cost-usd", 0.0))

            latency_gauge.labels(provider, model).set(latency)
            cost_gauge.labels(provider, model).set(cost)
            success_gauge.labels(provider, model).set(1)
        else:
            latency_gauge.labels(provider, model).set(latency)
            cost_gauge.labels(provider, model).set(0.0)
            success_gauge.labels(provider, model).set(0)

    except Exception as e:
        print(f"Error calling {provider}:{model} â†’ {e}")
        success_gauge.labels(provider, model).set(0)

    # Push metrics to Prometheus Pushgateway
    push_to_gateway(PUSHGATEWAY_URL, job="llm_benchmark", registry=registry)


with DAG(
    "model_benchmark",
    default_args=default_args,
    description="Benchmark LLM providers via Portkey Gateway",
    schedule_interval=timedelta(hours=1),  # run hourly
    start_date=datetime(2025, 8, 1),
    catchup=False,
    tags=["portkey", "benchmark"],
) as dag:

    for p in providers:
        task = PythonOperator(
            task_id=f"benchmark_{p['name']}_{p['model']}",
            python_callable=benchmark_provider,
            op_kwargs={"provider": p["name"], "model": p["model"]},
        )
```
```
providers.yaml
providers:
  - name: openai
    model: gpt-4o-mini
  - name: anthropic
    model: claude-3-5-sonnet
```
